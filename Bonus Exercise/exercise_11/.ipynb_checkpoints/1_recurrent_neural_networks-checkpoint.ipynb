{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent Neural Networks (RNN)\n",
    "====================\n",
    "\n",
    "In this exercise we will work with Recurrent Neural Networks (RNN). A RNN is class of neural networks where the output not only depends on the current input but also on previous inputs along a given input sequence. This allows to exhibit temporal dynamic behaviour and contextual information in a sequence. Common applications for RNN are:\n",
    "\n",
    "- time series analysis\n",
    "- speech recognition\n",
    "- machine translation\n",
    "- image captioning\n",
    "\n",
    "\n",
    "Goal of this exercise\n",
    "========\n",
    "\n",
    "This exercise notebook should help you to experiment how recurrent neural networks are implemented, trained, and used for computer vision problems. Therefore, this notebook is structured as follows:\n",
    "1. Implement your own simple RNN class in Pytorch.\n",
    "2. Explore the backpropagation of the gradients in the RNN and discuss the vanishing gradient problem.\n",
    "3. Implement your own LSTM (Long-Short Term Memory) Network and show that this architecture improves the vanishing gradient problem.\n",
    "4. Build RNN and LSTM classifier for the MNIST dataset and train your model.\n",
    "5. Submit your best model to the server to get bonus points.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using python:  3.7.4\n",
      "Using torch version:  1.4.0+cpu\n",
      "Using device:  cpu\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "print('Using python: ', platform.python_version())\n",
    "print('Using torch version: ', torch.__version__)\n",
    "print('Using device: ', device)\n",
    "# Machine: 2015 13\" Macbook Pro, i5 dual core"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAAlCAYAAACAjKdZAAAUzUlEQVR4Ae2dW+hFT1XHV9lFsovipazACo0CTbEiqEiDeuj+EobiQ4WVaNBDqNBDF/CpFCVQ0BQ1utAFutdDQRkWiOIVCXowNSMqKitT1C7y+bm/P77/+c/sPWefOXPmnDMDh9l79lzWfGetNWvWzN4nYoaJwPkR+LSI+LbzkzEpmAhMBCYCE4GJQBGBT59zVRGb+WAgBD4vIv5/+WFgzTARmAhMBCYCE4EREfgcm68+u0RgOpF9RkR8VkQ8LCIeERGPiYj3RMS/lyqY6VeHABb5Z0YEDMTvsRHxjxHxDyfoKfX/91Lv50fEfyVtiD8xvHKB57lnpXTq2HpGnrTOtTI5uk6VNuXzVMj2qRfZeqjpV3j+YxHx7j7NX2QrW7K39VydJh9hVNleyJvRBgIjyNCXRMQHFzqZK/9njebvMUsM5tPvBWuF5rOrQgCm1bh7/LMn6qXa+LJM/Y8u0KIyilPalL4W5xYKW+3lymTIPlnSlM+TQdulYl/pOm+em6+6dH5nIyzuHavS9RaGTISlsqRvld9J/izWGIGRZOhJC09leech1nEy/EtEvCsivtHSfyjjSbDH8/KKEEDJwAN4p77W+vXHEfHXdt/i8lVLGz8XEb+bqfB/I+I/l3afnnn+6oj4jYh4Q8Kf71/KPCEiHp6U+8uI+PmI+M3FE+uPaY8fyvyL/EFEvDAifjEi3puk97yd8tkT7fZtwVt4Z/80Ipw3f/oEstWe+vPUiCfgwxnMRM0fRsRrFpn+gBIz8ccX2X7K4jFUlg9FBPijE9bKK/+Mz4vASDL0zxHxxRHxTcsuyF/UQIMSl4WPF2OGegTwoHxdffZhc9IH8UBrr6WvIOWiXwPieUYLNLFy2Qp+dosyP7hVwJ6/Y2nvjZY20uWUz5FG43BaWFRItnLe2sNrvP4SqffqD3Z02XVC6uneUd0sckYERpAh3+Fhx2M1OPMxwcxQj4D2+1sbIvUUtMvpxk/r/sgwqDV25HbVZFRjjGksVOYZB0BDGWgcMUz5bD8qLCK+sn21xRrFk8SXvHDtiVsqzyy2Dg3oGzCfRtWhyG3n78kLUDOKDGnR/3dbEPHau4jew7xb9V/zcw4Xg11rQ+QcmJ3KsPpm46/aScVpAd+aVX6qiGvHRILCCnnEMOWz7aho1dnLkPZzIpvKuG1Xm9bWG7dUng/1Jgv3S8a86QA2rKw3L2gsmQvOPZ6a86EFB8BdyE1sP6yHEcHZmhnqEfjq+qw3m1MufM5I/d8JUWDv24PePvS09JrXZ18RES8d2GM15TMdtePuUYgEzub1CH5+9ZU9GjxRG71xo713Wl++wK5rLnVG9GtqMs88ByHQmxdGkiHOATKXEX5/ibMRIOmXM7yyhWbiHQKsosCu1jsyMmzuJWrVHz8nsbknbeCkb+xB21pIV7eMCXvyW+HXlvEbme8lm8Qj07mF9SjPxSu9jj2Ixxi/ntuPrfHujRv0syhz/oeGmiAvbys9VtPmLeXpzQujyZDPldnzv35+49wutktjzFMe9j4HFs4srRSSttlQjocECa6UKp8eWAvQq7yKt/hZ/T3kLNYaDad4NuWzParirV6GlfiRmG2ESw29cQMn1x/gV7OwII8wv1SsR6e7Ny9oPEeSIdF0N3+kgv0NNoJyU8OYj48IPmbH6+98LDL9kKMVu8lL9lbfYj3/QruuvcQr810R8cTlFWNe5/yt5fMHa3XA1Hw2wz/s+rdWgDH+iobjd0x9P7rQJdepkXnQ5Vctq9dcIVYMvD79/Ij4joj47iXTf+QyW9qblms+xTBqmPI56sjU0YVhrPC+5cOCbD/Lc8VHB3ud9RIdlxT/fUIsHy/e+nDxryxlvjwpO9ot+v9xywdj4Y10joVHNAfz2ZfVj1KO1rmG9IwqQ3zK51uWeedBc0jqYktXCLLKWP0zod96wMUMFsJlLS69iYIhoNf7Kc8Y+D31Z92Ly4ot16betvNXUj0fyrtUp8ZUHhzKwQeElxT6WlOfVjXUt+VxWpq7j3zVSfk1D5q2CygM5ur3msdKB+o1wd03PNjFlM/2AyK+7OGx0pYUPMlY5uQJWSr+VUb77u+usSduItJ1EhhuvcSCPAtr1TFazFjn5hCdRUX3wRPSY4pH8qz35IVRZchtpQfxmAbNYwrIs+VnZA59K+NBjV1BAtYzypGJ3o0hsCGNiZ0fedgqTAO4Cuv7NwqWTOm5opwSgaFpR8aE6nJ6YEQF364k71pwJUYf1L+99Xl/cn1Zo4VnrnygJxeol36JRmd20lFSaZBSuAR+1vh6POUzHdHD7jX+PQwrN4w1huJV6NAZTZ5xP3LoiZtw8K1wMIL314Iwzsn9Wrlez1jcikbpRAwtpfkiG/3p8wV5RulXT14YVYZkxDMujNV9ENO6dexuN2X0jvUeWNqj/VP9ag44C4c01jdSAHZL4FXWJ376lAY3Rqh3LcjrQj79cuOH0aXnqTHn9bthpfzH1McKS/XIUPf2tq5l2FFHyfsE7/JTcHwpl+NX4ZHrm+oZIYY++jCyfI6A06E09JwUxP+KU57ziRa+HDn0xE04qE3ht4aR5Bq9OGLwvnDtIdVb6GKC+qT+5/TZkrVrpL70WJyo74pHkSGXXRnJd4OQ/heZBjMdIXdf9x7Y1NAQuC3jvX1yYVgTeMfTjVT6kGvbDYrSmFAnRpLjkPOQkY8VsvKt0ZkaVlpZO/2H1Of45PqZ1pveOw45AVa/HCM35uhzqsC0OoSnRw+XIJ+jY5ijr9ekIMNYspf7ThpyoefEI4deuKUYOD45PUB+7ayUnqd1nuNeC3HXV6LDdaV70j19JP7oxQsjy5AwYFye4ROcDhYzuPx/W+lQYGmCFVOcMuZ/7B62HOLjIF/rH3Wf8ttKKTZvTxJywuIHvfkn7VL4N3vAf2C91e798m/8pvKa+v6skHdPfYWqVpPfvPIUpuY/2PjvMOfbv0rKPCq5/+3lnv8CPFXAwMXohcZjwiXI5zH9oyyrvj3ezGPb7VHeXzxAv7pnVe27PiYtvcejjrEgr6XO4aj8LcQ137J62wKEf++oNTbHyvXrIoIDz66vROMP6CIiftKumQv4715+a3OBFbmqyxYy1AOQx7kS09tTNPzildafbM9qjRBWEEzOOcPBqqu6/EhVrsvIhKeED1fy1t7LGuFDz8G6ZWhZH2+81PKN98EVKjzIpKN6fmbJ+P1eIHON4YxxTmClCM9/r9WzPGoWMQHqj6DBMOelqG3sUuSztj+ej7Hkz3AZR4yO0hk6L7N1jZHmfzJfyv/I5QEfnKwtw5/BHqqH/MOuuW1/yBA/l2jVtod4iom5dajFoBduaf9YYGkOYsvF9QB58eySzlvBh45R2lbp/li5lsH8I4UGeLtM4d26WN4EfL3db10eO++OxgstZGgLs6bP5TrF8CmdX6FB34qrdbNqu2tt26lpZ85Umbtp9/YVRsYjyMrUD2szLvwesHeb9NO37ta2tjzfGp2er0V9wmeNv5IuPeBW5YWFlBOYkcbzNICX8qf4adWflml1D33eNtd7vVbXKJ948TCgci9eHDsGrqfSMWh1L/6rpdXb9QWtl3eZI3+uDeeFNX3g9dZej4hbSnuqBxxLrsEN2T5VaCnXORp1POHYfhw7747IC61kKIf7sWkP2AoUU/oBP32/KtcQqwCFl+tiJaaxZy7Pa/5SZKWqq37EKuuXzbtBZ1m5Ixy/tHwf4xAA+M5Jy9Cyvq3vSZXoLq0+/2QpkOPbDySVsRWIxwzjlVX/Kb9tgxJoFa5RPvn7p5+ICL4fhtdw9e8gDgTyXyPi1w8oIx1VW4ZvDG15l7x5JikFfb9K9x4/1W8KbXyf5Un52x7tuhwNt1wn3pUkfuki0yT/zvKMbwGeKrSU6xyNfMtK4bW6ODBuMe+OxgstZehAOA/Ofn/kxFeNa6sgtxjxFGwFX4Gt1btVzyU895VUzhOU81aQlnqm0jf1dMgR7NcwdKxz7QvDc+UTPntXk043WMB/SnPDQ/0kBl/nWeFCmh8K9TItrzHg6C+/Eo017d2CfOIBZ1w0RjW4tMpDu7Ue+D1tIrfiw7VtTmGwRo8+yXBKemv7uEZnbR2H5pPMC099e04v7xzzZnctLa3kOtce/K++lV5AypXzNMdobc7wMsden5oXWsrQsX3Nlfe55gXyWPn5jdIqiMFSYNVV8iAoD/G3202LPznFDft7VmfrS1aiz2pd6WIA8FVlznz4SpcD535e4mmZtmsM2EyxYZPoL+PoOOwh9jER8efLalVfTU/rSY1ZeFAfT+Wr7KcOHPhn6+bYcCnyeWw/z1E+5ZFT0PCdVmnpjAwyobNDZM/tCECrzt/8qtV5jsseuOX6lS7M8OD9QkTIk/XcXKHGaa3kOkeWH2nw81WeF+wxZEqh9bxbakfpPXihlQyJ5pPGGFau+DkgXJrwOFyq8CJdLCtM/kJE4GoF8fHlMKqyPmG5YEsw9yaE8q3FHJj0SWYt795nz17BYG+duXJ4MGRU8fxbc5kKaRxi5dzTjxWej5jMwXGFNaWgPGmcvgWDUcUqBgOrFOBlDo0L559aJi+2WWsWBqV6e6Zfknz2xOVS2/pEgfD0DbY3ZPLdbzFEBAYavPGciOAvtNiuZ9G5V7dmmhsy6aMJVcwnMka+fsPgSIoOd8t8LA8TeutjGQrxYvH3aeki/ZTzboaMsyYdI0MQDsYssD932bn4o2XOJ/3HI+KflkV76c36XOdl//Dszvnj38cpueFlIctFKU8XlZAm92vuYJ/KKE5XHDki19I43IcX5xQ/79caDbln2uqinymOcs2CjwKYCZO17QGeKZ+EjvpTHNVGrn21SXyufMUv0zpxK9d+qFN4iO9Wit1/MV5liF0I1sqO8OzS5HMvZtoGS2Vnb3215aTbTrm15rqhxHt+JKD0dyV+LEB4EbuOkJFR2/+9+XrgVqIN3efyzHWPrf0SPYemo8vgc34+57DFqH6V5gT4JH0BqMe8u9bHHrzQSoZ0qB+50bY6mEuGPI28tcHn1bt5uub8hr8h4I1RAUTJWoYIKQ6fSPVcz2qJvaR8eKAkFKlyExZuWEkxUibN7/12JSLDivxrhtVafc4APfNhCAuf9ByZ97d0LeFVHcSulErlHGfKoLwuKdyKfGqcrtGwkvyXeNaN53TSdF5F6bs+kF4lD54MyUYPPSt5ZNx6B/GK+kuMsXIpwel2fvd+5XSz5lv4JQ0ac+c18YeepWVa3ffgBe9XTu/XyJB0qc8/SmNMhLnGZ00WU+y8/Tv6VAmxT/xeUANKHl9NIeTpBK9yvroq1au81xD7V2HTAdHgeT8RKGFfgyF5tYohTsvo8Cb51lZvng+6SsHztaiPdtRfVyal9tP0dFWms1JpvvTelVWKWZp3xHthRlySo2uQT43THt44Ztx6TArOu6lh74vWtTEWneIHFkgefGFX4hPPf+y16GHcegd5F4RFrS7oTWeuPbZvRTex+N1lmPS0T85DuXqVdo55twcveP/3yJDmZ7dfwExzM5graHzciaRnpVg8eT/3q5L7hExJLDDlY2UEkHKZ+RkQLypFeQ7Bczp6XgsTsJIRpL9VSQXFMSU/OOmgOqsvbRViCWMQCH+saq45Y8U4EMu9qTyqjzr0NlopHzSTD3pa15diLzr38oT3L627dC+8KJtORqUyo6T7pHsu+cTAhof2/lCCdyu4DVClLzTRbGRv9rjHpACx0gPwoXSmL14Y3zWDyHkh1SXUL8Xea/HQC7fcQLtM9+pvjo49aW4gwAvcyxuDLvZx1HzgfLIlS5KjvTp2T5968cIxMqSyaf80t/qxEjCWjKb5S/fIL+Opef9+wqbhteCuLirgJ1djWk5Ak6e3okxp6X0v40EYEZcsX4QKg8fz+rWMIleqPJenyYUUBmFw+XEthkEoCao3zad0xrJ1fUvT95FvV2wpiPtCdiGloT7Zo+Il/OeYFTMO+MBXt+eQT5dj8cmeuKQnHHKNbW99oT72mIjcm+A45gwlx4ZrL4ucpkGKXbohfd76viduKe1uaKAbLy1oknceYPzAlOBeFOWBP3PjvhS5izQmlOkpR2p3dBkSvsLMj6cwN+0Nfv4Xz+NdYBV/f6PEQkwFKElNwoVsDzggXVt3qa5LTMdooN/gVCv4uCq3yoD/HoNkFAzdcEvduTU0shrAED0kIDAI/KXidm75xLiDh/f+oD9VaLnxY4x6TwjQ0XNSoD34EEwO0Q2Ukzc8N3lRpybgLQM8h/2etN64OY1MiOBQY5B6uZGu0YXiA+I00EfNB8wNNYF6xAc9593evLBXhlIMcVwIL+bWvcEXPXvrqCrnrlq3slEmPQe8itiZqSsC8ujlJoiuhNxwYyPK57kMKxn7eAxGDZq4Soan7yZoEibtmMliC4tLwG2rD9f2/Fxyfam8oOM2yFUaDpEfGWcn9xJKSfrkKfDv9yDTnsz7m0DA3a+H7mPfBEAdOjmifIomJofege1xPEKjBryFUt65hameqQ/aQs7lbdnH0XFr2ddLqEsydI55d3ReQBZY1PtOCTQjO+n2uTx/OU9iyge+LY2Nc9KgAXYlKU8FE+sMt42ADmhqIrhtNPr3fkT51BmhQ7d6+6PXv0XfakiVtxasTBDsCBCka5fbGd0IAiPK9SjQa/GBMUVwgyjdUpYuWrKuRsqb1rFaaO9DNSYlqQPabi3urXuWuw4ExOiaDK6jV5fRixHkk20q9AHnHKQfxBO41Emf+uJT/KTzVYxbGtywYoUtI0wvvqT55/31IjCCXI+Irm+lI0voHukaYtKQI7bRhWGNt0ovY8lYO3nf5Yp24o85dX9ygmcD3RHANSv+gPFn6IfACPLp4w8foND4yT0v3uiHyrgtSdmXDqZjiAov4lK+cXs4KWuBwAhy3aIfp6hDCw7JCTLFIXg/Z8Uz9A84bgU31mpfUNuqs/o52346TFldaGa8GQTE7H4m4GY6P0BHp3wOMAgVJKDEt/QokwR5iGe4bQSmXOfHHznKYYO3inR+tUGfxOCQ+wwTgeEQ0Hmr9ADhcIROgiYCE4GJwETg5hGQUeVnyG8elAnAeAhwlgY37NwSHG9sJkUTgYnARGAi8CkEtN26eobxk3V9Hwvp+6GBAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Recurrent Neural Network\n",
    "\n",
    "The recurrent loops in a RNN allow relevant information to persist over time. A simple RNN architecture is shown here:\n",
    "<img src=http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-rolled.png width=\"150\">\n",
    "\n",
    "A simple RNN takes not only an input X at time step t but also passes a hidden state that is the output of the previous time step into the network. The output of a RNN cell at time step t reads in Eq. 1:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "In this task you have to implement a simple one-layer RNN as a class in Pytorch, where you can choose a relu or tanh activation in the cell.You can see the architecture of a simple RNN in the figure below.\n",
    "\n",
    "#### Define your model in the provided file `exercise_code/rnn/rnn_nn.py` file\n",
    "\n",
    "\n",
    "<img src=http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-SimpleRNN.png width=\"600\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T0D0: Implement the RNN class\n",
    "from exercise_code.rnn.rnn_nn import RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, Pytorch already has implemented a simple RNN in their library and you can call the RNN with <code>nn.RNN</code>. We will use the Pytorch RNN function to check if we have built the correct cell and compare the output of both functions. We also compare the running time of both classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'Tensor' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b87a28cd2fa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# The difference of outputs should be 0!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_pytorch\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0moutput_i2dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Differnce between pytorch and your RNN implementation: %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'Tensor' and 'list'"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import timeit\n",
    "\n",
    "# choose your network parameters\n",
    "input_size=3\n",
    "hidden_dim=3\n",
    "seq_len= 10 \n",
    "\n",
    "# define the two models\n",
    "pytorch_rnn=nn.RNN(input_size, hidden_dim)\n",
    "i2dl_rnn=RNN(input_size, hidden_dim)\n",
    "\n",
    "# initialise both rnn with same values\n",
    "for p in pytorch_rnn.parameters():\n",
    "    nn.init.constant_(p, val=0.3)\n",
    "for p in i2dl_rnn.parameters():\n",
    "    nn.init.constant_(p, val=0.3)\n",
    "    \n",
    "X=torch.randn(seq_len, 1, input_size)\n",
    "\n",
    "output_pytorch, h_pytorch = pytorch_rnn(X)\n",
    "output_i2dl, h_i2dl = i2dl_rnn(X)\n",
    "\n",
    "\n",
    "# The difference of outputs should be 0!!\n",
    "\n",
    "diff = torch.sum((output_pytorch-output_i2dl)**2)\n",
    "print(\"Differnce between pytorch and your RNN implementation: %s\" %diff.item())\n",
    "if diff.item()<10**-10:\n",
    "    print(\"Cool, you implemented a correct model.\")\n",
    "else:\n",
    "    print(\"Upps! There is something wrong in your model. Try again!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "runs=10**4\n",
    "\n",
    "print(\"Time Pytorch RNN {} runs: {:.3f}s\".format(runs, timeit.timeit(\"pytorch_rnn(X)\", \n",
    "                                       setup=\"from __main__ import pytorch_rnn, X\", \n",
    "                                       number=runs))\n",
    "     )\n",
    "\n",
    "print(\"Time I2DL RNN {} run: {:.3f}s\".format(runs, timeit.timeit(\"i2dl_rnn(X)\", \n",
    "                                       setup=\"from __main__ import i2dl_rnn, X\", \n",
    "                                       number=runs))\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on we will use the Pytorch module that is faster and optimised in performance. However, it is always a good exercise to build the functions by yourself and we really advice you to do the exercise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanishing Gradient\n",
    "\n",
    "As discussed in the lecture, the simple RNN suffers from vanishing gradients in the backpropagation. The hidden state is manipulated in every time step along the sequence and the effect of the past inputs to the final output vanishes with the distance in time. In the next cell we will explore the vanishing effect of previous inputs in the RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hidden_size=1\n",
    "input_size= 1\n",
    "\n",
    "time_steps=50\n",
    "rnn=RNN(input_size, hidden_size, 'tanh')\n",
    "X = torch.randn(time_steps, 1, input_size)\n",
    "X.requires_grad=True\n",
    "_,h=rnn(X)\n",
    "h.requires_grad\n",
    "h.sum().backward()\n",
    "grad_tanh=X.grad.view(-1)\n",
    "\n",
    "plt.semilogy(np.flip(abs(grad_tanh.detach().cpu().numpy())), label=\"Tanh\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time step t\")\n",
    "plt.ylabel(\"d h_T/d x_t\")\n",
    "plt.title(\"Log plot of gradient of output wrt. input\")\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <h3>Note</h3>\n",
    "    <p>It can be seen that the gradient of the of the output at time t wrt. to a previous input decreases exponentially. Hence, the final output does not change significantly for changes in the previous input and hence the RNN does not have memory.</p> \n",
    "<h3>Question</h3> \n",
    "<p>In order to better understand the vanishing gradient problem, calculate the gradients \n",
    "dh_t/dV, dh_t /dW, and dh_t/dX_0 analytically for t=3 and h_0=0 using Eq. 1. This exercise might seem a little bit tedious but it is really useful. Can you explain the vanishing gradient mathematically based on your findings?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long-Short Term Memory Network (LSTM)\n",
    "The vanishing gradient problem had been known for some time until Schmidhuber (1997) developed the Long-Short Term Memory Network and showed that this architecture can overcome the problem. <br> \n",
    "A LSTM is a more advanced recurrent network architecture that is able to learn long time dependencies. The architecture of a LSTM is composed of a forget, input, and output gate and the cell can remember values over arbitrary time intervals. Despite various different and exotic LSTM architectures, the standard LSTM cell is shwon in the figure below:\n",
    "\n",
    "\n",
    "<img src=http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png width=\"600\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to a simple RNN the LSTM cell has a hidden vector and an additional cell state vector. __What size does the cell state have?__ <br>\n",
    "The operations inside the LSTM are given as \n",
    "\n",
    "<img src=https://wikimedia.org/api/rest_v1/media/math/render/svg/2db2cba6a0d878e13932fa27ce6f3fb71ad99cf1  width=\"600\">\n",
    "where \n",
    "f_t: forget gate,  <br>\n",
    "i_t: input gate, <br>\n",
    "o_t: output gate, <br>\n",
    "h_t: hidden state vector, <br>\n",
    "c_t: cell state vector, <br>\n",
    "x_t: input vector, <br>\n",
    "t is time step, \n",
    "<br> \n",
    "<br> \n",
    "and<br> \n",
    "sigma_g: sigmoid activation <br> \n",
    "sigma_c and sigma_h: hyperbolic tangent function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step you should implement your own LSTM with the operations stated above.\n",
    "#### Define your model in the provided file `exercise_code/rnn/rnn_nn.py` file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement the RNN class\n",
    "from exercise_code.rnn.rnn_nn import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# choose your input parameters\n",
    "input_size=3\n",
    "hidden_dim=3\n",
    "seq_len= 10 \n",
    "\n",
    "# define the two models\n",
    "pytorch_lstm=nn.LSTM(input_size, hidden_dim)\n",
    "i2dl_lstm=LSTM(input_size, hidden_dim)\n",
    "\n",
    "# initialise both lstms with same values\n",
    "for p in pytorch_lstm.parameters():\n",
    "    nn.init.constant_(p, val=0.3)\n",
    "for p in i2dl_lstm.parameters():\n",
    "    nn.init.constant_(p, val=0.3)\n",
    "    \n",
    "X=torch.randn(seq_len, 1, input_size)\n",
    "\n",
    "output_pytorch, (h_pytorch, _) = pytorch_lstm(X)\n",
    "output_i2dl , (h_i2dl, _ )= i2dl_lstm(X)\n",
    "\n",
    "# The difference of outputs should be 0!!\n",
    "diff = torch.sum((output_pytorch-output_i2dl)**2)\n",
    "print(\"Differnce between pytorch and your RNN implementation: %s\" %diff.item())\n",
    "if diff.item()<10**-10:\n",
    "    print(\"Cool, you implemented a correct model.\")\n",
    "else:\n",
    "    print(\"Upps! There is something wrong in your model. Try again!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "runs=10**4\n",
    "\n",
    "print(\"Time Pytorch LSTM {} runs: {:.3f}s\".format(runs, timeit.timeit(\"pytorch_lstm(X)\", \n",
    "                                       setup=\"from __main__ import pytorch_lstm, X\", \n",
    "                                       number=runs))\n",
    "     )\n",
    "\n",
    "print(\"Time I2DL LSTM {} run: {:.3f}s\".format(runs, timeit.timeit(\"i2dl_lstm(X)\", \n",
    "                                       setup=\"from __main__ import i2dl_lstm, X\", \n",
    "                                       number=runs))\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Gradients\n",
    "Analogously to the RNN, calculate the gradients of the input wrt. to the output of the LSTM and compare it against the RNN gradients. __What do you see?__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hidden_size=1\n",
    "input_size= 1\n",
    "\n",
    "time_steps=50\n",
    "rnn=RNN(input_size, hidden_size)\n",
    "X = torch.randn(time_steps, 1, input_size)\n",
    "X.requires_grad=True\n",
    "_,h=rnn(X)\n",
    "h.requires_grad\n",
    "h.sum().backward()\n",
    "grad_rnn=X.grad.view(-1)\n",
    "\n",
    "lstm=LSTM(input_size, hidden_size)\n",
    "X = torch.randn(time_steps, 1, input_size)\n",
    "X.requires_grad=True\n",
    "_,(h, c)=lstm(X)\n",
    "h.sum().backward()\n",
    "grad_lstm=X.grad.view(-1)\n",
    "\n",
    "plt.semilogy(np.flip(abs(grad_lstm.detach().cpu().numpy())) , label=\"LSTM\")\n",
    "plt.semilogy(np.flip(abs(grad_rnn.detach().cpu().numpy())), label=\"RNN\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time step t\")\n",
    "plt.ylabel(\"d h_T/d x_t\")\n",
    "plt.title(\"Log plot of gradient of output wrt. input\")\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST image classification with RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <h3>Note</h3>\n",
    "    <p>\n",
    "    In this semester you have seen three different types of neural networks, namely Multi-Layer Perceptrons (MLPs), Convolutional Neural Networks (CNNs), and now Recurrent Neural Networks (RNNs). We have seen that we can use all three architectures for image classification. However, it turned out that some models are better than others for image classification. Try to think about advantages and disadvantages of the models, regarding # of parameters, transformations of the object in the image (scaling, rotation, translation,...), training time, testing time, over-fitting, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Prepare MNIST Dataset \n",
    "\n",
    "In this exercise, we will solve the problem of image classification with a recurrent neural network.  \n",
    "\n",
    "For the experiment we use the MNIST handwritten digits dataset which we already know from the autoencoder exercise. This dataset consists of images of the 10 different digits (10 classes). The images have the resolution 28 x 28. \n",
    "\n",
    "To acquire the dataset, you can simply run the following code or use the alternative link we provided to download manually.\n",
    "\n",
    "After successfully downloading the MNIST dataset, let's visualize some examples from the dataset, we will show a few examples of training images from each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exercise_code.util.download_utils import download_dataset\n",
    "download_url = 'http://filecremers3.informatik.tu-muenchen.de/~dl4cv/mnist_train.zip'\n",
    "i2dl_exercises_path = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "data_root = os.path.join(i2dl_exercises_path, 'datasets','mnist')\n",
    "\n",
    "download_dataset(\n",
    "    url=download_url,\n",
    "    data_dir=data_root,\n",
    "    dataset_zip_name='mnist_data.zip',\n",
    "    force_download=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# loading the train data\n",
    "from exercise_code.rnn.mnist_dataset import *\n",
    "\n",
    "import pickle\n",
    "from torchvision import transforms\n",
    "    \n",
    "# transformation of data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])\n",
    "\n",
    "# read dataset\n",
    "path = os.path.join(data_root,\"mnist_train.p\")\n",
    "\n",
    "with open(path, \"rb\") as f:\n",
    "    mnist_raw = pickle.load(f)\n",
    "\n",
    "# split the dataset\n",
    "X, y= mnist_raw\n",
    "train_split=0.85\n",
    "train_dset=MnistDataset(X[:int(len(X)*train_split)], y[:int(len(X)*train_split)], transform=transform)\n",
    "val_dset=MnistDataset(X[int(len(X)*train_split):], y[int(len(X)*train_split):], transform=transform)\n",
    "\n",
    "\n",
    "X=train_dset.images\n",
    "y=train_dset.labels\n",
    "\n",
    "# training sample visualization\n",
    "classes = list(range(10))\n",
    "num_classes = len(classes)\n",
    "samples_per_class = 5\n",
    "for y_hat, cls in enumerate(classes):\n",
    "    idxs = np.flatnonzero(train_dset.labels == y_hat)\n",
    "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + y_hat + 1\n",
    "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "        plt.imshow(X[idx])\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Design your own model\n",
    "Now it is your turn to build your own model. The idea for the RNN classifier and LSTM classifier is to interpret the image as a sequence of rows. This means that we pass the rows through the RNN or LSTM and use the final hidden state for classification. To do so, you may use RNN and LSTM network you just wrote and add linear layer(s) for classfication at the end of your model. You can also checke the following architecture as a hint for your classifer design.\n",
    "\n",
    "<img src=https://cdn-images-1.medium.com/max/800/1*Cm_c-I02rBa1rtLZXBhNUw.png width=\"600\">\n",
    "\n",
    "#### Define your classifier in the provided file `exercise_code/rnn/classifier.py` file\n",
    "\n",
    "This file is mostly empty but contains the expected class name, and the methods that your model (RNN_Classifier and LSTM_Classifier) needs to implement (only `__init__()` and `forward()` basically). \n",
    "The only rules your model design has to follow are:\n",
    "* Inherit from pytorch_lightning.LightningModule, which we have implemented in base_classifier.py\n",
    "* Define necessary layers in your classifier model in `__init__()`\n",
    "* Perform the forward pass in `forward()`, predicting the class of a given MNIST sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Train your model\n",
    "In addition to the network itself, you will also need to write the code for the model training. You may use PyTorch Lightning (stronly recomanded) to define a trainer for that, or you can also write it yourself in standard PyTorch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Train your RNN classifier\n",
    "\n",
    "In this part, you need to train your RNN classifier at first. With your simple RNN classifier you should exceed an accuracy higher than __90%__.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exercise_code.rnn.classifier import RNN_Classifier\n",
    "\n",
    "path =os.path.join(data_root,\"mnist_train.p\")\n",
    "model_rnn = RNN_Classifier()\n",
    "model_rnn.set_data_path(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "########################################################################\n",
    "# TODO - Train Your Model                                              #\n",
    "########################################################################\n",
    "\n",
    "\n",
    "############################################################################\n",
    "#                             END OF YOUR CODE                             #\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Train  your LSTM classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you may try to imporve your model by using LSTM intead of RNN, notes that you need to submit your LSTM model for final evaluation to get bonus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exercise_code.rnn.classifier import LSTM_Classifier\n",
    "\n",
    "path = os.path.join(data_root,\"mnist_train.p\")\n",
    "\n",
    "model_lstm = LSTM_Classifier()\n",
    "model_lstm.set_data_path(path)\n",
    "model_lstm.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "########################################################################\n",
    "# TODO - Train Your Model                                              #\n",
    "########################################################################\n",
    "\n",
    "\n",
    "############################################################################\n",
    "#                             END OF YOUR CODE                             #\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Your Model\n",
    "\n",
    "When you are satisfied with your training, you can save your LSTM classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exercise_code.util import save_model\n",
    "save_model(model_lstm, \"lstm_mnist_nn.p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Instructions\n",
    "1. Go on [our submission page](https://dvl.in.tum.de/teaching/submission/), register for an account and login. We use your matriculation number and send an email with the login details to the mail account associated. When in doubt, login into tum online and check your mails there. You will get an ID which we need in the next step.\n",
    "2. Navigate to `exercise_code` directory and run the `create_submission.sh` file to create the zip file of your model. This will create a single `zip` file that you need to upload. Otherwise, you can also zip it manually if you don't want to use the bash script. However, **make sure that the structure of the zip file is the same** as it would be when generated with the bash-script.\n",
    "3. Log into [our submission page](https://dvl.in.tum.de/teaching/submission/) with your account details and upload the `zip` file. Once successfully uploaded, you should be able to see the submitted file selectable on the top.\n",
    "4. Click on this file and run the submission script. You will get an email with your score as well as a message if you have surpassed the threshold.\n",
    "\n",
    "# Submission Goals\n",
    "\n",
    "- Goal: Implement and train a convolutional neural network for facial keypoint detection.\n",
    "- Passing Criteria: Reach **Score >= 90** on __our__ test dataset. The submission system will show you your score after you submit.\n",
    "\n",
    "- Submission start: __Thrusday, June 10, 2020 - 12:00__\n",
    "- Submission deadline : __Wednesday, July 16, 2020 - 23:59__ \n",
    "- There is no limit for the number of submissions. Your __best submission__ will be considered for bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
